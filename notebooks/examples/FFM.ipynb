{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Fast & Fusiest Mapper (FFM)\n",
    "This notebook shows how to run the Fast & Fusiest Mapper (FFM) on a full workload and\n",
    "architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize the specification. The spec is initialized with a `ff.Spec` object\n",
    "using YAML files (though you may also initialize them with Python objects).\n",
    "\n",
    "When loading specifications, Jinja2 templating can be used, and the `jinja_parse_data`\n",
    "parameter can be used to pass in data to the templating engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < DOC_INCLUDE_MARKER > make_spec\n",
    "\n",
    "import fastfusion as ff\n",
    "\n",
    "# Set the number of parallel threads that the mapper can use. If you are running out of\n",
    "# memory, you may decrease this number. By default the number of threads is set to the\n",
    "# number of cores on your machine.\n",
    "import os\n",
    "ff.set_n_parallel_jobs(os.cpu_count(), print_message=True)s\n",
    "\n",
    "# Initialize the specification and show the workload.\n",
    "BATCH_SIZE = 1\n",
    "N_TOKENS = 16384\n",
    "FUSE = True\n",
    "\n",
    "spec = ff.Spec.from_yaml(\n",
    "    \"../../examples/arches/tpu_v4i_like.arch.yaml\",\n",
    "    \"../../examples/workloads/gpt3_6.7B.workload.yaml\",\n",
    "    jinja_parse_data=dict(\n",
    "        BATCH_SIZE=BATCH_SIZE,\n",
    "        N_TOKENS=N_TOKENS,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fusion happens when tensors bypass the outermost Memory object, so, to disable fusion,\n",
    "# force all tensors to be in the outermost memory.\n",
    "if not FUSE:\n",
    "    for node in spec.arch.nodes:\n",
    "        if isinstance(node, ff.arch.Memory):\n",
    "            print(f'Keeping all tensors in {node.name}')\n",
    "            node.constraints.tensors.keep = \"All\"\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll visualize the workload. The workload is a cascade of Einsums, with boxes\n",
    "showing Einsums (computation steps), ovals showing tensors, and arrows showing\n",
    "dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set optimization metrics for the mapper. Note that having more metrics will\n",
    "make the mapper slower because it is more difficult to prune suboptimal mappings,\n",
    "because it must prove that something is Pareto-dominated in all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimization metrics\n",
    "spec.mapper.ffm.metrics = ff.mapper.FFM.Metrics.ENERGY\n",
    "# spec.mapper.ffm.metrics = ff.mapper.FFM.Metrics.LATENCY\n",
    "# spec.mapper.ffm.metrics = ff.mapper.FFM.Metrics.LATENCY | ff.mapper.FFM.Metrics.ENERGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- < DOC_INCLUDE_MARKER > FFM_parts -->\n",
    "\n",
    "The mapper consists of two parts:\n",
    "\n",
    "- The Turbo-Charged Pmapper: This part makes all Pareto-optimal pmappings for all\n",
    "  Einsums.\n",
    "- Fast and Fusiest: This part takes the Pareto-optimal pmappings and joins them into\n",
    "  full mappings.\n",
    "\n",
    "Mapping begins with the Turbo-Charged Pmapper with the `make_pmappings` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < DOC_INCLUDE_MARKER > make_pmappings\n",
    "\n",
    "# Commenting this will be slower, but may generate better mappings. Limits the number of\n",
    "# fused loops that can exist in a single pmapping.\n",
    "spec.mapper.ffm.max_fused_loops = 1\n",
    "\n",
    "pmappings = ff.mapper.FFM.make_pmappings(\n",
    "    spec,\n",
    "    # Having can_combine_multiple_runs=False is faster, so it should generally be set to\n",
    "    # True. If it is set to False, then you may run make_pmappings multiple times with\n",
    "    # compatible specs and combine them:\n",
    "    #   pmappings = make_pmappings(*args_a) | make_pmappings(*args_b)\n",
    "    can_combine_multiple_runs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < DOC_INCLUDE_MARKER > pmappings_stats\n",
    "\n",
    "# Output some stats about the generated pmappings.\n",
    "print(f\"Total number of pmappings: {pmappings.n_total_pmappings()}\")\n",
    "print(f\"Number of valid pmappings: {pmappings.n_valid_pmappings()}\")\n",
    "print(f\"Number of Pareto-optimal pmappings: {pmappings.n_pareto_optimal_pmappings()}\")\n",
    "print(f\"Number of evaluated pmappings: {pmappings.n_evaluated_pmappings()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < DOC_INCLUDE_MARKER > join_pmappings\n",
    "\n",
    "# Join the pmappings to create a full mapping.\n",
    "mappings = ff.mapper.FFM.join_pmappings(spec,pmappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The joined pmappings object contains a DataFrame of all Pareto-optimal pmappings for\n",
    "# the given optimization metrics. Since we're only interested in one metric, this should\n",
    "# have exaclty one row, but we'll grab index 0 to be sure.\n",
    "mapping = mappings[0]\n",
    "\n",
    "# All units are SI units-- seconds, joules, meters, etc.\n",
    "print(f\"Totals:\")\n",
    "\n",
    "# The access method accesses all columns that include Total as a susb\n",
    "for k, v in mapping.access(\"Total\").to_dict().items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the mapping.\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessor = \"latency\" if spec.mapper.ffm.metrics == ff.mapper.FFM.Metrics.LATENCY else \"energy\"\n",
    "per_compute = mapping.access(\"Total\").per_compute().to_dict()[accessor]\n",
    "print(f'Per-compute {accessor}: {per_compute}')\n",
    "\n",
    "print(f'Contributors to {accessor}:')\n",
    "for k, v in mapping.access(accessor).to_dict().items():\n",
    "    print(f\"\\t{k}: {v}\")\n",
    "\n",
    "# Print the other stats\n",
    "for k, v in mapping.to_dict().items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
