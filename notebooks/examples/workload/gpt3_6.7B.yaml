# Each tensor is shaped by a set of ranks, denoted by capital letters
# For example: Q is shaped by (B, M, H, E)
# We'll use lower-case letters to index into the ranks
# For example: Q[b, m, h, e] is the tensor Q at index (b, m, h, e)

# When making a projection list, it's equivalent to the Einsum subscript notation, so:
# Q projection [b, m, h, e] means that b indexes into B, m indexes into M...
# When making a projection dict, it's equivalent to the Einsum subscript/superscript notation, so:
# K projection { B: b, M: p, H: h, E: e } means that b indexes into B, p indexes into M...

# Renames take a tensor name and turn them into a canonical name that we can use in
# architecture constraints. For example, we want to use the words "input", "weight", and
# "output" to refer to the tensors of an Einsum, but the Einsum QK has no clear "weight"
# or "input" because both Q and K are inputs. So we rename K to be weight.


workload:
  version: "0.5"
  shape:
    {% set BATCH_SIZE = BATCH_SIZE | default(1) %}
    b: 0 <= b < {{BATCH_SIZE}}
    {% set N_TOKENS = N_TOKENS | default(8192) %}
    m: 0 <= m < {{N_TOKENS}} # = b
    p: 0 <= p < {{N_TOKENS}} # = m
    h: 0 <= h < 32
    e: 0 <= e < 128
    f: 0 <= f < 128
    d: 0 <= d < 4096 # = e * h
    c: 0 <= c < 16384
    j: 0 <= j < 4096
    g: 0 <= g < 4096

  einsums:
  - name: I
    # Copy operation means that we move the input tensor from one place to another
    # without doing computation. This lets us copy the input tensor onto the accelerator
    # once and then use it in the Q, K, and V operations.
    is_copy_operation: True
    tensor_accesses:
    - {name: I_in, projection: [b, m, d]}
    - {name: I, projection: [b, m, d], output: True}
    renames: {weight: Nothing(), input: Inputs(), output: Outputs()}

  - name: V
    tensor_accesses:
    - {name: I, projection: [b, m, d]}
    - {name: WV, projection: [h, e, d]}
    - {name: V, projection: [b, m, h, e], output: True}

  - name: K
    tensor_accesses:
    - {name: I, projection: [b, m, d]}
    - {name: WK, projection: [h, e, d]}
    - {name: K, projection: [b, m, h, e], output: True}

  - name: Q
    tensor_accesses:
    - {name: I, projection: [b, m, d]}
    - {name: WQ, projection: [h, e, d]}
    - {name: Q, projection: [b, m, h, e], output: True}

  - name: QK
    tensor_accesses:
    - {name: Q, projection: [b, m, h, e]}
    - {name: K, projection: { B: b, M: p, H: h, E: e }}
    - {name: QK, projection: [b, m, p, h], output: True}
    renames: {weight: K, input: Q, output: QK}

  - name: QK_softmax
    tensor_accesses:
    - {name: QK, projection: [b, m, p, h]}
    - {name: QK_softmax, projection: [b, m, p, h], output: True}
    renames: {weight: Nothing()}

  - name: AV
    tensor_accesses:
    - {name: QK_softmax, projection: [b, m, p, h]}
    - {name: V, projection: { B: b, M: p, H: h, E: f}}
    - {name: AV, projection: [b, m, h, f], output: True}
    renames: {weight: V, input: QK_softmax}

  - name: Z
    tensor_accesses:
    - {name: AV, projection: [b, m, h, f]}  
    - {name: WZ, projection: [h, f, g]}
    - {name: Z, projection: [b, m, g], output: True}

  - name: FFA
    tensor_accesses:
    - {name: Z, projection: [b, m, g]}
    - {name: WFFA, projection: [g, c]}
    - {name: FFA, projection: [b, m, c], output: True}

  - name: FFB
    tensor_accesses:
    - {name: FFA, projection: [b, m, c]}
    - {name: WFFB, projection: [c, j]}
    - {name: FFB, projection: [b, m, j], output: True}

# Inputs(): Inputs to this Einsum
# Intermediates(): Produced by some Einsum and consumed by some other Einsum
# Outputs(): Outputs of this Einsum
# Nothing(): Empty set

renames:
  einsums:
  - name: default
    tensor_accesses:
    - name: input
      source: Inputs() & Intermediates()
      expected_count: 1
    - name: output
      source: Outputs()
      expected_count: 1
    - name: weight
      source: ~(input | output)
      expected_count: 1