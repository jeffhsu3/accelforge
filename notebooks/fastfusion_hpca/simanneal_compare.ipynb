{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Fast & Fusiest Mapper (FFM)\n",
    "This notebook shows how to run the Fast & Fuseiest Mapper (FFM) on a full workload and\n",
    "architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import fastfusion as ff\n",
    "from IPython.display import SVG, display\n",
    "import os\n",
    "ff.set_n_parallel_jobs(32)#os.cpu_count(), print_message=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the specification and show the workload.\n",
    "BATCH_SIZE = 4\n",
    "N_TOKENS = 4096\n",
    "FUSE = True\n",
    "\n",
    "spec = ff.Spec.from_yaml(\n",
    "    # \"arches/tpu_v4i_like.yaml\",\n",
    "    \"arches/tpu_v4i_like_constrained.yaml\",\n",
    "    # \"arches/simple.arch.yaml\",\n",
    "    \"workloads/gpt3_6.7B.yaml\",\n",
    "    # \"workloads/matmuls8_mixed.workload.yaml\",\n",
    "    jinja_parse_data=dict(\n",
    "        BATCH_SIZE=BATCH_SIZE,\n",
    "        N_TOKENS=N_TOKENS,\n",
    "    )\n",
    ")\n",
    "\n",
    "# If fusion is disabled, keep all tensors in main memory.\n",
    "if not FUSE:\n",
    "    spec.arch.nodes[\"MainMemory\"].constraints.tensors.keep = \"All()\"\n",
    "\n",
    "# display(SVG(spec.workload.render()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the pmappings.\n",
    "\n",
    "# Set optimization metrics\n",
    "# spec.mapper.ffm.metrics = ff.mapper.FFM.Metrics.ENERGY\n",
    "# spec.mapper.ffm.metrics = ff.mapper.FFM.Metrics.LATENCY\n",
    "spec.mapper.ffm.metrics = ff.mapper.FFM.Metrics.LATENCY | ff.mapper.FFM.Metrics.ENERGY\n",
    "spec.mapper.ffm.max_fused_loops = 2\n",
    "\n",
    "pmappings = ff.mapper.FFM.make_pmappings(\n",
    "    spec,\n",
    "    can_combine_multiple_runs=False,\n",
    "    cache_dir=\"cache\",\n",
    ")\n",
    "\n",
    "# Simanneal before:\n",
    "# -- number of pmappings per Einsum\n",
    "# ++ per-Pmapping runtime\n",
    "\n",
    "# Changes:\n",
    "# + pmappings per Einsum\n",
    "# - per-pmapping runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output some stats about the generated pmappings.\n",
    "print(f\"Total number of pmappings: {pmappings.total_pmappings()}\")\n",
    "print(f\"Number of valid pmappings: {pmappings.valid_pmappings()}\")\n",
    "print(f\"Number of Pareto-optimal pmappings: {pmappings.pareto_optimal_pmappings()}\")\n",
    "print(f\"Number of evaluated pmappings: {pmappings.evaluated_pmappings()}\")\n",
    "print(f\"Number of evaluated pmappings for simanneal baseline compare: {pmappings._evaluated_pmappings_for_simanneal_baseline_compare()}\")\n",
    "\n",
    "# Total number of pmappings: 1299665056477.98\n",
    "# Number of valid pmappings: 346954061.15200764\n",
    "# Number of Pareto-optimal pmappings: 334167\n",
    "# Number of evaluated pmappings: 282649104 / 9105032\n",
    "\n",
    "\n",
    "# Total number of pmappings: 934266468234.9056\n",
    "# Number of valid pmappings: 96623713.66167709\n",
    "# Number of Pareto-optimal pmappings: 20457134\n",
    "# Number of evaluated pmappings: 177651824\n",
    "# Number of evaluated pmappings for simanneal baseline compare: 21663787806.54472\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "s = \"energy\" if spec.mapper.ffm.metrics == ff.mapper.FFM.Metrics.ENERGY else \"latency\"\n",
    "\n",
    "if spec.mapper.ffm.metrics == ff.mapper.FFM.Metrics.ENERGY:\n",
    "    s = \"energy\"\n",
    "    acc = lambda x: x[f\"Total<SEP>{s}\"]\n",
    "elif spec.mapper.ffm.metrics == ff.mapper.FFM.Metrics.LATENCY:\n",
    "    s = \"latency\"\n",
    "    acc = lambda x: x[f\"Total<SEP>{s}\"]\n",
    "elif spec.mapper.ffm.metrics == ff.mapper.FFM.Metrics.LATENCY | ff.mapper.FFM.Metrics.ENERGY:\n",
    "    s = \"EDP\"\n",
    "    acc = lambda x: x[f\"Total<SEP>energy\"] * x[f\"Total<SEP>latency\"]\n",
    "\n",
    "class FilterLambda:\n",
    "    def __init__(\n",
    "        self,\n",
    "        best_edp: float,\n",
    "        min_latency: float,\n",
    "        min_energy: float,\n",
    "    ):\n",
    "        self.best_edp = best_edp\n",
    "        self.min_latency = min_latency\n",
    "        self.min_energy = min_energy\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        a = acc(x) <= self.best_edp\n",
    "        b = x[\"Total<SEP>energy\"] * self.min_latency <= self.best_edp\n",
    "        c = x[\"Total<SEP>latency\"] * self.min_energy <= self.best_edp\n",
    "        return a & b & c\n",
    "\n",
    "SIMANNEAL = True\n",
    "\n",
    "if not SIMANNEAL:\n",
    "    # ff.set_n_parallel_jobs(1, print_message=True)\n",
    "    \n",
    "    def filter_lambda(pm):\n",
    "        return all(len(x.loops) == 0 for x in pm.compatibility.tensors)\n",
    "\n",
    "    mappings = ff.mapper.FFM.join_pmappings(spec, pmappings.filter(filter_lambda))\n",
    "    \n",
    "    min_latency = sum(min(s.mappings.data[f'Total<SEP>latency'].min() for s in sg) for sg in pmappings.einsum2pmappings.values() )\n",
    "    min_energy = sum(min(s.mappings.data[f'Total<SEP>energy'].min() for s in sg) for sg in pmappings.einsum2pmappings.values() )\n",
    "    \n",
    "    print(f\"Min latency: {min_latency}\")\n",
    "    print(f\"Min energy: {min_energy}\")\n",
    "\n",
    "    f = FilterLambda(\n",
    "        best_edp=acc(mappings[0]),\n",
    "        min_latency=min_latency,\n",
    "        min_energy=min_energy,\n",
    "    )\n",
    "    \n",
    "    print(f\"Filtering pmappings with {s} > {acc(mappings[0])}\")\n",
    "\n",
    "    # Join the pmappings to create a full mapping.\n",
    "    mappings = ff.mapper.FFM.join_pmappings(\n",
    "        spec,\n",
    "        pmappings,\n",
    "        pmapping_row_filter_function=f\n",
    "    )\n",
    "else:\n",
    "    # Join the pmappings to create a full mapping.\n",
    "    ff.set_n_parallel_jobs(32, print_message=True)\n",
    "    tracker = ff.mapper.simanneal2.join_pmappings(\n",
    "        spec,\n",
    "        pmappings,\n",
    "        score_target=0.04982001853,\n",
    "        max_evaluations=20,\n",
    "    )\n",
    "    for a, b in tracker.history:\n",
    "        print(f\"{a} {b}\")\n",
    "\n",
    "# B=4 M=4096 GPT3 6.7B constrained EDP:\n",
    "#   No fusion 0.0767265063452541\n",
    "#   No tiled fusion 0.07461399646709636\n",
    "#   One loop 0.05170420468561774\n",
    "#   Two loops 0.04982001852997137 <- FAST\n",
    "#   Tiled fusion 0.04982001853\n",
    "# Totals:\n",
    "# \tlatency: 0.06004345904761903\n",
    "# \tenergy: 0.8297326523187198\n",
    "# \tmapping: <fastfusion.mapper.FFM._interface.main.MappingFromRow object at 0x7f0726c4e8a0>\n",
    "\n",
    "# Brief progress update on where I've been this week: Struggled with sim annealing because I implemented it using the new tile shape exploration & results changed quite a lot, but I think I fixed it.\n",
    "# The way it works is that it'll randomly mutate compatibility, pick the relevant SIMs, and pick one of the chosen pmappings for that SIM. The pmappings have already been Pareto pruned, so I charge them (#Evaluated pmappings by tile shape exploration / # pareto-optimal pmappings) evaluations for this, being the expected value of the #pmappings to check before finding a Pareto-optimal one.\n",
    "# The problem is that the new pmapper can find all the pareto-optimal pmappings with orders-of-magnitude fewer evaluated pmappings, so the sim annealing results had unusually low evaluations. Did some debugging and the low evaluations was somewhat due to information leakage. When the pmapper explores, it prunes partially-constructed mappings. It also waits until last to enumerate fused loops, so we get a lot of cases where one act of pruning would affect many different SIMs. This wouldn't be possible with sim annealing because in theory it should be making the fused loops before doing other intra-Einsum choices, so this cross-sim pruning wouldn't benefit it. I added a tracker for that in the pmapping explore and now simanneal is good and slow \n",
    "\n",
    "# Though, I wonder now if this is leaking contribution from fast pmapper into fast & fusiest... FFM gives the fast pmapper larger mapspaces to explore (full pmapping space) than simannealing would (pmapping space for a given fused loop choice), so the pmapper for FFM can leverage more pruning opportunities in this space. (edited) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The joined pmappings object contains a DataFrame of all Pareto-optimal pmappings for\n",
    "# the given optimization metrics. Since we're only interested in one metric, this should\n",
    "# have exaclty one row, but we'll grab index 0 to be sure.\n",
    "mappings = mappings[0]\n",
    "\n",
    "# Show the mapping.\n",
    "display(SVG(mappings.render()))\n",
    "\n",
    "# All units are SI units-- seconds, joules, meters, etc.\n",
    "print(f\"Totals:\")\n",
    "for k, v in mappings.access(\"Total\").to_dict().items():\n",
    "    print(f\"\\t{k}: {v}\")\n",
    "\n",
    "for k in \"energy\", \"latency\":\n",
    "    try:\n",
    "        per_compute = mappings.access(\"Total\").per_compute().to_dict()[k]\n",
    "        print(f'Per-compute {k}: {per_compute}')\n",
    "    except:\n",
    "        print(f'No per-compute {k}')\n",
    "\n",
    "print(f'Contributors to {s}:')\n",
    "for k, v in mappings.access(s).to_dict().items():\n",
    "    print(f\"\\t{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the other stats\n",
    "for k, v in mappings.to_dict().items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
