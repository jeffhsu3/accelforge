{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from hwcomponents_cacti import SRAM as CactiSRAM\n",
    "from hwcomponents_library import AladdinAdder, AladdinMultiplier\n",
    "\n",
    "from fastfusion.frontend.architecture import Memory\n",
    "from fastfusion.frontend.specification import Specification\n",
    "from fastfusion.mapper.FFM.exploration.mapper_multi_einsum import get_sims\n",
    "from fastfusion.mapper.simanneal.wrappers import join_sims\n",
    "\n",
    "import copy\n",
    "import time\n",
    "from fastfusion import Specification\n",
    "from fastfusion.mapper.metrics import Metrics\n",
    "from fastfusion.mapper.FFM.exploration.mapper_multi_einsum import get_sims\n",
    "from fastfusion.mapper.FFM.joining.sim import SIM\n",
    "from fastfusion.mapper.FFM.joining.simexplore import join_sims\n",
    "import fastfusion.mapper.FFM.exploration.mapper_one_einsum as mapper_one_einsum\n",
    "\n",
    "from fastfusion.mapper.FFM.exploration.mapping_filter_tags.ffmt import get_ffmt_tag\n",
    "from fastfusion.mapper.FFM.exploration.mapping_filter_tags.onesplit import get_one_split_tag\n",
    "from fastfusion.mapper.FFM.pareto import PartialMappings\n",
    "\n",
    "# TODO: Make a setting for the below two in the spec\n",
    "# TODO: Generate pmappings one Einsum at a time. Once we've made compatibility, check it\n",
    "# against the previously-generated compatibilities and stop if there's no match.\n",
    "# TODO: Once the previous is done, also add a forward check. Once the compatibilities of\n",
    "# a particular Einsum are generated, we can immediately check the previous Einsums.\n",
    "\n",
    "\n",
    "objective = lambda df: df['Total_Latency']# * df['Total_Energy']\n",
    "\n",
    "def get_fused_mappings(\n",
    "        n_pes,\n",
    "        pe_x,\n",
    "        pe_y,\n",
    "        parameterization=\"\",\n",
    "        return_mappings=False,\n",
    "        cache_dir=\"cache\",\n",
    "    ) -> PartialMappings:\n",
    "    print(f'Running parameterization {parameterization}')\n",
    "    cachekey = (n_pes, pe_x, pe_y, parameterization)\n",
    "    fname = parameterization + \" \" + hashlib.md5(str(cachekey).encode()).hexdigest()\n",
    "    if os.path.exists(f\"{cache_dir}/{fname}.pkl\"):\n",
    "        print(f\"Loading from {cache_dir}: {fname}\")\n",
    "        mappings = pickle.load(open(f\"{cache_dir}/{fname}.pkl\", \"rb\"))\n",
    "        if return_mappings:\n",
    "            return mappings\n",
    "        return objective(mappings.data).min(), mappings\n",
    "    return 0, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parameterization2edp = {}\n",
    "parameterization2mappings = {}\n",
    "\n",
    "parameterizations = [\n",
    "    \"Unfused\",\n",
    "    \"FlashAttention A\",\n",
    "    \"FlashAttention B\",\n",
    "    \"Fixed-Dataflow\",\n",
    "    \"FFM\"\n",
    "]\n",
    "\n",
    "results_keys = [\n",
    "    \"Big-Batch\\n256 PEs\\n\",\n",
    "    \"Big-Batch\\n64 PEs\",\n",
    "    \"Big-Sequence\\n256 PEs\",\n",
    "    \"Big-Sequence\\n64 PEs\",\n",
    "]\n",
    "results = {}\n",
    "\n",
    "for cache_dir in [\"cache\", \"cache2\"]:\n",
    "    for n_pes in [256, 64]:\n",
    "        parameterization2result = {}\n",
    "        for p in parameterizations:\n",
    "            x, _ = get_fused_mappings(n_pes, 128, 128, parameterization=p, cache_dir=cache_dir)\n",
    "            print(f\"{p} {n_pes}x128x128: {x}\")\n",
    "            parameterization2result[p] = x\n",
    "        results[results_keys.pop(0)] = parameterization2result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "def plot_default_formatting(ax, grid_axis='both'):\n",
    "    ax.tick_params(axis='both', which='major')#, labelsize=20)\n",
    "    ax.tick_params(axis='both', which='minor')#, labelsize=20)\n",
    "    legend = ax.legend()\n",
    "    legend.get_frame().set_facecolor('white')\n",
    "    legend.get_frame().set_edgecolor('black')\n",
    "    # Set legend ncols to 5\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "    ax.legend(fontsize=14, ncols=5)\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(axis=grid_axis, which='major', linestyle='-', linewidth='0.3', color='gray')\n",
    "    ax.grid(axis=grid_axis, which='minor', linestyle='--', linewidth='0.1', color='lightgray')\n",
    "    \n",
    "\n",
    "colors = [\n",
    "    \"#1f77b4\",\n",
    "    \"#ff7f0e\",\n",
    "    \"#2ca02c\",\n",
    "    \"#9467bd\",\n",
    "    \"#ff0000\",\n",
    "]\n",
    "\n",
    "def make_bar_chart(\n",
    "    data,\n",
    "    title,\n",
    "    xlabel,\n",
    "    ylabel,\n",
    "    y_scale,\n",
    "    output_file=None,\n",
    "    normalize: bool = False,\n",
    "    ylim=(None, None),\n",
    "    xlim=(None, None),\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a bar chart from the given data and save it as a PDF.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    if isinstance(data, dict) and isinstance(next(iter(data.values())), dict):\n",
    "        bar_width = 0.8 / len(data)\n",
    "        keys = list(next(iter(data.values())).keys())\n",
    "        x = range(len(keys))\n",
    "        first = next(iter(data.values()))\n",
    "            \n",
    "        for i, (label, values) in enumerate(data.items()):\n",
    "            bar_positions = [pos + i * bar_width for pos in x]\n",
    "            to_plot = values\n",
    "            if normalize:\n",
    "                to_plot = {k: v / first[k] for k, v in values.items()}\n",
    "            bars = plt.bar(bar_positions, to_plot.values(), width=bar_width, label=label, color=colors[i])\n",
    "        plt.xticks([pos + (len(data) - 1) * bar_width / 2 for pos in x], keys)\n",
    "        # plt.legend(loc='upper right', fontsize=10)\n",
    "        plt.legend(fontsize=10, ncol=len(data), loc='upper center')\n",
    "    else:\n",
    "        keys = list(data.keys())\n",
    "        bars = plt.bar(keys, data.values())\n",
    "\n",
    "    # Set logarithmic scale for Y-axis if specified\n",
    "    if y_scale == 'log':\n",
    "        plt.yscale('log')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "\n",
    "    # Rotate X-axis labels vertically\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plot_default_formatting(plt.gca(), grid_axis='y')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    fig = plt.gcf()\n",
    "    bbox = ax.get_tightbbox(fig.canvas.get_renderer())\n",
    "    x0, y0, width, height = bbox.transformed(fig.transFigure.inverted()).bounds\n",
    "    # slightly increase the very tight bounds:\n",
    "    xpad = 0.05 * width\n",
    "    ypad = 0.05 * height\n",
    "    fig.add_artist(plt.Rectangle((x0-xpad, y0-ypad), width+2*xpad, height+2*ypad, edgecolor='red', linewidth=3, fill=False))\n",
    "    \n",
    "    if output_file is not None:\n",
    "        with open(output_file, 'wb') as f:\n",
    "            plt.savefig(f, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Now we're going to make a line chart. Have the X axis be (Number of MACs, GLB size)\n",
    "# and the Y axis be EDP. We'll plot a line for each parameterization.\n",
    "\n",
    "# # Get the keys from parameterization2edp\n",
    "# keys = list(parameterization2edp.keys())\n",
    "# entries = {}\n",
    "# for key in keys:\n",
    "#     print(key)\n",
    "#     parts = key.split(\" \")\n",
    "#     mac_dims = parts[-1]\n",
    "#     n_pes = int(parts[-2])\n",
    "#     n_macs = int(mac_dims.split(\"x\")[0]) * int(mac_dims.split(\"x\")[1]) * n_pes\n",
    "#     entry = \" \".join(parts[:-2])\n",
    "#     n_macs = f\"{n_macs // 1024}k\"\n",
    "#     entries.setdefault(entry, {})[n_macs] = 1 / (parameterization2edp[key] / 1.05e9 * 1000)\n",
    "    \n",
    "# max_throughput = max(max(e.values()) for e in entries.values())\n",
    "# entries = {k: {k2: v2 / max_throughput for k2, v2 in v.items()} for k, v in entries.items()}\n",
    "    \n",
    "# all_keys = set.union(*[set(entries.keys()) for entries in entries.values()])\n",
    "# for name, e in entries.items():\n",
    "#     for k in all_keys:\n",
    "#         if k not in e:\n",
    "#             e[k] = 0\n",
    "#     entries[name] = {k: e[k] for k in sorted(e.keys(), key=lambda x: int(x.split(\"k\")[0]))}\n",
    "\n",
    "entries = {}\n",
    "\n",
    "name_changes = {\n",
    "    \"Unfused\": \"Elementwise-Only\",\n",
    "    \"FlashAttention A\": \"FlashAttention A\",\n",
    "    \"FlashAttention B\": \"FlashAttention B\",\n",
    "    \"FFM\": \"Fast & Fusiest\",\n",
    "}\n",
    "\n",
    "for k, v in results.items():\n",
    "    entries[k] = {name_changes.get(k2, k2): 1/v[k2] if v[k2] else 0 for k2 in v}\n",
    "    max_val = max(entries[k].values())\n",
    "    for k2, v2 in entries[k].items():\n",
    "        entries[k][k2] = v2 / max_val if max_val else 0\n",
    "        \n",
    "# Transpose everything\n",
    "entries2 = {}\n",
    "for k, v in entries.items():\n",
    "    for k2, v2 in v.items():\n",
    "        entries2.setdefault(k2, {})[k] = v2\n",
    "entries = entries2\n",
    "        \n",
    "# Print as a table\n",
    "for name, e in entries2.items():\n",
    "    print(f\"{name}: {e}\")\n",
    "\n",
    "make_bar_chart(entries, title=None, xlabel=None, ylabel=\"Throughput (normalized)\", y_scale='linear', output_file=\"mapsapce_compare.pdf\", normalize=False, ylim=(0, 1.14), xlim=(None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # glb_MB = 128\n",
    "# # sram_MB = 4\n",
    "# # parameterization = \"\"\n",
    "\n",
    "# # cur_area_budget = area_budget\n",
    "# # glb_size = glb_MB * 1024 * 1024 * 8\n",
    "# # glb = CactiSRAM(technology=\"7e-9\", width=1024, depth=glb_size // 1024)\n",
    "# # cur_area_budget -= glb.get_area()\n",
    "# # # for sram_MB in [0.25, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4]:\n",
    "# # sram_size = sram_MB * 1024 * 1024 * 8\n",
    "# # llb = CactiSRAM(technology=\"7e-9\", width=128, depth=sram_size // 128)\n",
    "# # remaining_area = cur_area_budget / 4 - llb.get_area() # Per-MXU\n",
    "# # mac_dims = int((remaining_area / mac_area) ** 0.5)\n",
    "# # print(f\"Global buffer: {glb_MB} MB, Local buffer: {sram_MB} MB, MAC dims: {mac_dims}x{mac_dims}\")\n",
    "# # print(f'GLB read energy: {glb.read()}. LLB read energy: {llb.read()}')\n",
    "\n",
    "from fastfusion.mapper.FFM.exploration.mapper_multi_einsum import get_per_tensor_size, get_num_computes\n",
    "for tensor, size in sorted(get_per_tensor_size(spec).items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{tensor}: {size}\")\n",
    "print(f\"Number of computes: {get_num_computes(spec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfusion.mapper.FFM.exploration.mapper_multi_einsum import get_rank_variable_bounds_for_all_einsums\n",
    "\n",
    "parameterization2latencycols: list[dict[str, float]] = []\n",
    "for p, mappings in parameterization2mappings.items():\n",
    "    mappings._data = mappings.data.sort_values(by=\"Total_Latency\", ascending=True)\n",
    "    rank_variable_bounds = get_rank_variable_bounds_for_all_einsums(spec)\n",
    "\n",
    "    row = {\n",
    "        \"Parameterization\": p,\n",
    "    }\n",
    "    for col in mappings.data.columns:\n",
    "        print(f'{col}: {mappings.data.iloc[0][col]}')\n",
    "        # if \"Latency\" in col:\n",
    "        # if \"Total_Latency\" in col:\n",
    "        if \"Latency\" in col:\n",
    "        # if \"Total_Energy\" in col:\n",
    "            row[col] = mappings.data.iloc[0][col]\n",
    "    parameterization2latencycols.append(row)\n",
    "\n",
    "    # from fastfusion.mapper.FFM.deprecate_maybe.visualization import make_mapping\n",
    "    # from IPython.display import SVG\n",
    "    # newmapping = make_mapping(mappings.data.iloc[0], spec.workload.einsum_names, get_rank_variable_bounds_for_all_einsums(spec))\n",
    "    # for col in mappings.data.columns:\n",
    "    #     print(f'{col}: {mappings.data.iloc[0][col]}')\n",
    "\n",
    "    # display(SVG(newmapping.render()))\n",
    "    \n",
    "from fastfusion.accelerated_imports.pd import DataFrame\n",
    "df = DataFrame(parameterization2latencycols)\n",
    "from fastfusion.accelerated_imports import pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "df\n",
    "    \n",
    "# {'n1'}-1 || [GlobalBuffer] T1 sz 0 above 1\n",
    "# TODO: Re-add -1 to the mapper one eisnum freenig\n",
    "# compatibility2sims['Matmul1'][\"{'n1'}-1 || [GlobalBuffer] T1 sz 0 above 1\"]\n",
    "# Above 1: 8192\n",
    "# Above 2: 8321\n",
    "# compatibility2sims['Matmul2'][\"{'n1'}-1 || [GlobalBuffer] T1 sz 0 above 1, [GlobalBuffer] T2 sz 0 above 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastfusion.mapper.FFM.exploration.mapper_multi_einsum import get_rank_variable_bounds_for_all_einsums\n",
    "\n",
    "mac_dims = int((((area_budget - glb.get_area()) / 4 - llb.get_area()) / mac_area)** 0.5)\n",
    "mappings = list(parameterization2mappings.values())[0]\n",
    "mappings._data = mappings.data.sort_values(by=\"Total_Latency\", ascending=True).head()\n",
    "rank_variable_bounds = get_rank_variable_bounds_for_all_einsums(spec)\n",
    "from fastfusion.mapper.FFM.deprecate_maybe.visualization import make_mapping\n",
    "from IPython.display import SVG\n",
    "newmapping = make_mapping(mappings.data.iloc[0], spec.workload.einsum_names, get_rank_variable_bounds_for_all_einsums(spec))\n",
    "a = {}\n",
    "for col in mappings.data.columns:\n",
    "    print(f'{col}: {mappings.data.iloc[0][col]}')\n",
    "    if \"Latency\" in col:\n",
    "        a[col] = mappings.data.iloc[0][col]\n",
    "display(SVG(newmapping.render()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False\n",
    "\n",
    "from fastfusion.mapper.FFM.exploration.mapper_multi_einsum import get_rank_variable_bounds_for_all_einsums\n",
    "\n",
    "sram_size = 0.5 * 1024 * 1024 * 8\n",
    "llb = CactiSRAM(technology=\"7e-9\", width=128, depth=sram_size // 128)\n",
    "mac_dims = int((((area_budget - glb.get_area()) / 4 - llb.get_area()) / mac_area)** 0.5)\n",
    "mappings = get_fused_mappings(\n",
    "    spec,\n",
    "    mac_dims,\n",
    "    llb,\n",
    "    glb,\n",
    "    return_mappings=True,\n",
    "    parameterization=\"FFM\"\n",
    ")\n",
    "mappings._data = mappings.data.sort_values(by=\"Total_Latency\", ascending=True).head()\n",
    "rank_variable_bounds = get_rank_variable_bounds_for_all_einsums(spec)\n",
    "from fastfusion.mapper.FFM.deprecate_maybe.visualization import make_mapping\n",
    "from IPython.display import SVG\n",
    "newmapping = make_mapping(mappings.data.iloc[0], spec.workload.einsum_names, get_rank_variable_bounds_for_all_einsums(spec))\n",
    "b = {}\n",
    "for col in mappings.data.columns:\n",
    "    print(f'{col}: {mappings.data.iloc[0][col]}')\n",
    "    if \"Latency\" in col:\n",
    "        b[col] = mappings.data.iloc[0][col]\n",
    "display(SVG(newmapping.render()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([a, b])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
