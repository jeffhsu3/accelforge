{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage of the Mapper\n",
    "\n",
    "This notebook shows advanced usage for the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize the spec. The spec is initialized with a `af.Spec` object\n",
    "using YAML files (though you may also initialize them with Python objects).\n",
    "\n",
    "When loading specifications, Jinja2 templating can be used, and the `jinja_parse_data`\n",
    "parameter can be used to pass in data to the templating engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "examples_dir = Path(\"../../examples\")\n",
    "\n",
    "# < DOC_INCLUDE_MARKER > make_spec\n",
    "import accelforge as af\n",
    "\n",
    "# Set the number of parallel threads that the mapper can use. If you are running out of\n",
    "# memory, you may decrease this number. By default the number of threads is set to the\n",
    "# number of cores on your machine.\n",
    "import os\n",
    "af.set_n_parallel_jobs(os.cpu_count(), print_message=True)\n",
    "\n",
    "# Initialize the spec and show the workload.\n",
    "BATCH_SIZE = 1\n",
    "N_TOKENS = 8192\n",
    "FUSE = False\n",
    "spec = af.Spec.from_yaml(\n",
    "    examples_dir / \"arches\" / \"tpu_v4i.yaml\",\n",
    "    examples_dir / \"workloads\" / \"gpt3_6.7B.yaml\",\n",
    ")\n",
    "# Fusion happens when tensors bypass the outermost Memory object, so, to disable fusion,\n",
    "# force all tensors to be in the outermost memory.\n",
    "if not FUSE:\n",
    "    for node in spec.arch.nodes:\n",
    "        if isinstance(node, af.arch.Memory):\n",
    "            print(f'Keeping all tensors in {node.name}')\n",
    "            node.tensors.keep = \"All\"\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first visualize the architecture. The architecture is a tree, starting at the top\n",
    "with the outermost memory level. Each leaf of the tree is a `Compute` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll visualize the workload. The workload is a cascade of Einsums, with boxes\n",
    "showing Einsums (computation steps), ovals showing tensors, and arrows showing\n",
    "dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll set optimization metrics for the mapper. Note that having fewer metrics is\n",
    "faster, because it makes it easier to prune suboptimal mappings. A mapping is suboptimal\n",
    "if and only if another mapping is better in all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimization metrics\n",
    "spec.mapper.ffm.metrics = af.mapper.FFM.Metrics.ENERGY\n",
    "# spec.mapper.ffm.metrics = af.mapper.FFM.Metrics.LATENCY\n",
    "# spec.mapper.ffm.metrics = af.mapper.FFM.Metrics.LATENCY | af.mapper.FFM.Metrics.ENERGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workloads can be mapped onto the architecture in one step using the `spec.map_workload_to_arch` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < DOC_INCLUDE_MARKER > map_workload_to_arch\n",
    "\n",
    "# Commenting this will be slower, but may generate better mappings. Limits the number of\n",
    "# fused loops that can exist in a single pmapping.\n",
    "spec.mapper.ffm.max_fused_loops = 1\n",
    "mapping =spec.map_workload_to_arch()\n",
    "\n",
    "# Render the mapping with mapping.render(), or in the last line of a notebook:\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the energy and latency of the resulting mapping using the `energy` and\n",
    "`latency` attributes of the mapping object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# < DOC_INCLUDE_MARKER > mapping_stats\n",
    "\n",
    "print(f'Energy: {mapping.energy()}J, {mapping.per_compute().energy()}J/compute')\n",
    "for k, v in mapping.per_compute().energy(per_component=True).items():\n",
    "    print(f'\\t{k}: {v}J/compute')\n",
    "\n",
    "print(f'Latency: {mapping.latency()}s, {mapping.per_compute().latency()}s/compute')\n",
    "for k, v in mapping.per_compute().latency(per_component=True).items():\n",
    "    print(f'\\t{k}: {v}s/compute')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
